"""
æ–‡æœ¬è™•ç†å·¥å…·
æä¾›å„ç¨®æ–‡æœ¬åˆ†æžå’Œè™•ç†åŠŸèƒ½
"""
from langchain.tools import Tool
import re
from collections import Counter

class TextLengthTool:
    """æ–‡æœ¬é•·åº¦è¨ˆç®—å·¥å…·"""
    
    def __init__(self):
        self.name = "text_length"
        self.description = "è¨ˆç®—æ–‡æœ¬çš„å­—ç¬¦é•·åº¦"
    
    def calculate_length(self, text: str) -> str:
        """è¨ˆç®—æ–‡æœ¬é•·åº¦"""
        try:
            length = len(text)
            return f"æ–‡æœ¬é•·åº¦: {length} å€‹å­—ç¬¦"
        except Exception as e:
            return f"éŒ¯èª¤: {e}"
    
    def get_langchain_tool(self) -> Tool:
        """ç²å– LangChain å·¥å…·å°è±¡"""
        return Tool(
            name=self.name,
            description=self.description,
            func=self.calculate_length
        )

class TextCountTool:
    """æ–‡æœ¬çµ±è¨ˆå·¥å…·"""
    
    def __init__(self):
        self.name = "text_counter"
        self.description = "çµ±è¨ˆæ–‡æœ¬ä¸­çš„å–®è©žã€è¡Œæ•¸ç­‰è³‡è¨Š"
    
    def count_text(self, text: str) -> str:
        """çµ±è¨ˆæ–‡æœ¬"""
        try:
            lines = text.split('\n')
            words = text.split()
            characters = len(text)
            
            # çµ±è¨ˆä¸åŒé¡žåž‹çš„å­—ç¬¦
            letters = sum(c.isalpha() for c in text)
            digits = sum(c.isdigit() for c in text)
            spaces = sum(c.isspace() for c in text)
            
            result = f"""æ–‡æœ¬çµ±è¨ˆçµæžœ:
ðŸ“Š åŸºæœ¬çµ±è¨ˆ:
- ç¸½å­—ç¬¦æ•¸: {characters}
- å–®è©žæ•¸: {len(words)}
- è¡Œæ•¸: {len(lines)}

ðŸ”¤ å­—ç¬¦åˆ†é¡ž:
- å­—æ¯: {letters}
- æ•¸å­—: {digits}
- ç©ºæ ¼å’Œæ›è¡Œ: {spaces}
- æ¨™é»žç¬¦è™Ÿ: {characters - letters - digits - spaces}"""
            
            return result
        except Exception as e:
            return f"çµ±è¨ˆéŒ¯èª¤: {e}"
    
    def get_langchain_tool(self) -> Tool:
        """ç²å– LangChain å·¥å…·å°è±¡"""
        return Tool(
            name=self.name,
            description=self.description,
            func=self.count_text
        )

class TextAnalyzerTool:
    """æ–‡æœ¬åˆ†æžå·¥å…·"""
    
    def __init__(self):
        self.name = "text_analyzer"
        self.description = "æ·±åº¦åˆ†æžæ–‡æœ¬å…§å®¹ï¼ŒåŒ…æ‹¬é »çŽ‡çµ±è¨ˆã€èªžè¨€ç‰¹å¾µç­‰"
    
    def analyze_text(self, text: str) -> str:
        """åˆ†æžæ–‡æœ¬"""
        try:
            # åŸºæœ¬çµ±è¨ˆ
            char_count = len(text)
            word_count = len(text.split())
            line_count = len(text.split('\n'))
            
            # å–®è©žé »çŽ‡åˆ†æž
            words = re.findall(r'\b\w+\b', text.lower())
            word_freq = Counter(words)
            most_common = word_freq.most_common(5)
            
            # å­—ç¬¦é »çŽ‡åˆ†æž
            char_freq = Counter(text.lower())
            common_chars = [(char, count) for char, count in char_freq.most_common(5) if char.isalpha()]
            
            # å¥å­åˆ†æž
            sentences = re.split(r'[.!?]+', text)
            sentences = [s.strip() for s in sentences if s.strip()]
            avg_sentence_length = sum(len(s.split()) for s in sentences) / len(sentences) if sentences else 0
            
            result = f"""ðŸ“ˆ æ·±åº¦æ–‡æœ¬åˆ†æžå ±å‘Š:

ðŸ“Š åŸºæœ¬çµ±è¨ˆ:
- å­—ç¬¦æ•¸: {char_count}
- å–®è©žæ•¸: {word_count}
- è¡Œæ•¸: {line_count}
- å¥å­æ•¸: {len(sentences)}
- å¹³å‡å¥å­é•·åº¦: {avg_sentence_length:.1f} å€‹å–®è©ž

ðŸ”¤ æœ€å¸¸è¦‹å–®è©ž:"""
            
            for word, count in most_common:
                result += f"\n- '{word}': {count} æ¬¡"
            
            result += "\n\nðŸ”  æœ€å¸¸è¦‹å­—æ¯:"
            for char, count in common_chars:
                result += f"\n- '{char}': {count} æ¬¡"
            
            # èªžè¨€ç‰¹å¾µ
            avg_word_length = sum(len(word) for word in words) / len(words) if words else 0
            result += f"\n\nðŸ“ èªžè¨€ç‰¹å¾µ:\n- å¹³å‡å–®è©žé•·åº¦: {avg_word_length:.1f} å€‹å­—ç¬¦"
            
            return result
        except Exception as e:
            return f"åˆ†æžéŒ¯èª¤: {e}"
    
    def get_langchain_tool(self) -> Tool:
        """ç²å– LangChain å·¥å…·å°è±¡"""
        return Tool(
            name=self.name,
            description=self.description,
            func=self.analyze_text
        )

class TextTransformTool:
    """æ–‡æœ¬è½‰æ›å·¥å…·"""
    
    def __init__(self):
        self.name = "text_transformer"
        self.description = "è½‰æ›æ–‡æœ¬æ ¼å¼ï¼ŒåŒ…æ‹¬å¤§å°å¯«è½‰æ›ã€åè½‰ç­‰"
    
    def transform_text(self, text: str, operation: str = "upper") -> str:
        """è½‰æ›æ–‡æœ¬"""
        try:
            operations = {
                "upper": lambda t: t.upper(),
                "lower": lambda t: t.lower(),
                "title": lambda t: t.title(),
                "reverse": lambda t: t[::-1],
                "capitalize": lambda t: t.capitalize(),
                "swapcase": lambda t: t.swapcase()
            }
            
            if operation not in operations:
                available_ops = ", ".join(operations.keys())
                return f"éŒ¯èª¤: ä¸æ”¯æ´çš„æ“ä½œ '{operation}'ã€‚å¯ç”¨æ“ä½œ: {available_ops}"
            
            transformed = operations[operation](text)
            return f"è½‰æ›çµæžœ ({operation}):\n{transformed}"
        except Exception as e:
            return f"è½‰æ›éŒ¯èª¤: {e}"
    
    def get_langchain_tool(self) -> Tool:
        """ç²å– LangChain å·¥å…·å°è±¡"""
        return Tool(
            name=self.name,
            description=self.description,
            func=lambda text_and_op: self.transform_text(*text_and_op.split('|', 1) if '|' in text_and_op else (text_and_op, "upper"))
        )

class TextValidatorTool:
    """æ–‡æœ¬é©—è­‰å·¥å…·"""
    
    def __init__(self):
        self.name = "text_validator"
        self.description = "é©—è­‰æ–‡æœ¬æ ¼å¼ï¼Œå¦‚é›»å­éƒµä»¶ã€URLã€é›»è©±è™Ÿç¢¼ç­‰"
    
    def validate_text(self, text: str, validation_type: str = "email") -> str:
        """é©—è­‰æ–‡æœ¬"""
        try:
            patterns = {
                "email": r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$',
                "url": r'^https?://(?:[-\w.])+(?:[:\d]+)?(?:/(?:[\w/_.])*(?:\?(?:[\w&=%.])*)?(?:#(?:[\w.])*)?)?$',
                "phone": r'^\+?1?-?\.?\s?\(?(\d{3})\)?[\s.-]?(\d{3})[\s.-]?(\d{4})$',
                "ip": r'^(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)$'
            }
            
            if validation_type not in patterns:
                available_types = ", ".join(patterns.keys())
                return f"éŒ¯èª¤: ä¸æ”¯æ´çš„é©—è­‰é¡žåž‹ '{validation_type}'ã€‚å¯ç”¨é¡žåž‹: {available_types}"
            
            pattern = patterns[validation_type]
            is_valid = bool(re.match(pattern, text.strip()))
            
            return f"é©—è­‰çµæžœ ({validation_type}):\næ–‡æœ¬: '{text}'\nçµæžœ: {'âœ… æœ‰æ•ˆ' if is_valid else 'âŒ ç„¡æ•ˆ'}"
        except Exception as e:
            return f"é©—è­‰éŒ¯èª¤: {e}"
    
    def get_langchain_tool(self) -> Tool:
        """ç²å– LangChain å·¥å…·å°è±¡"""
        return Tool(
            name=self.name,
            description=self.description,
            func=lambda text_and_type: self.validate_text(*text_and_type.split('|', 1) if '|' in text_and_type else (text_and_type, "email"))
        )

# ä¾¿æ·å‡½æ•¸
def create_text_length_tool() -> TextLengthTool:
    """å‰µå»ºæ–‡æœ¬é•·åº¦å·¥å…·"""
    return TextLengthTool()

def create_text_count_tool() -> TextCountTool:
    """å‰µå»ºæ–‡æœ¬çµ±è¨ˆå·¥å…·"""
    return TextCountTool()

def create_text_analyzer_tool() -> TextAnalyzerTool:
    """å‰µå»ºæ–‡æœ¬åˆ†æžå·¥å…·"""
    return TextAnalyzerTool()

def create_text_transform_tool() -> TextTransformTool:
    """å‰µå»ºæ–‡æœ¬è½‰æ›å·¥å…·"""
    return TextTransformTool()

def create_text_validator_tool() -> TextValidatorTool:
    """å‰µå»ºæ–‡æœ¬é©—è­‰å·¥å…·"""
    return TextValidatorTool()